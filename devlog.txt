NUTSHELL DEVLOG

=== 2025-10-28: Initial implementation ===

Built basic working version of nutshell - CLI tool for summarizing research papers with Claude API.

Current state:
- Core functionality working: PDF in, markdown summary out
- Using Claude 3.5 Haiku (claude-3-5-haiku-20241022) - supports PDF input, cheap for dev work
- Tested with one paper (LLM Agents in Interaction), produced good summary
- Modular code structure: separate functions for PDF loading, prompt creation, API calls, file I/O
- Git repo initialized, 2 commits so far

Key decisions made:
- PDF analysis (full document) vs text extraction: chose PDF because Haiku 3.5 supports it
  Means figures/tables/formatting preserved. Can revisit later if needed.
- Model selection is parameterized, easy to swap for prompt engineering phase
- Kept initial version simple: no research focus param yet, just core loop working

What's working:
- API integration solid
- PDF handling clean
- Output quality looks good (but only one test case so far)

What's untested:
- Different paper types (math-heavy, very long, short letters, multi-column layouts)
- Edge cases (malformed PDFs, rate limits, network issues)
- Prompt quality across diverse content
- Token usage for large papers (might hit max_tokens limit)

Next steps:
- Test with diverse papers to validate robustness
- Refine prompt based on learnings
- Then add features (research focus param, etc)

Notes:
- API key stored in .env (gitignored)
- Sample paper in project dir for quick testing
- Prompt is unmodified from original - probably needs refinement after more testing
- max_tokens set to 4096, might need adjustment for comprehensive summaries

=== 2025-10-28: Infrastructure testing ===

Ran comprehensive tests across 7 diverse papers:
- 6-page bio paper with diagrams
- 9-page AI paper
- Math-heavy two-column physics paper
- Social sciences experimental stats paper
- 41-page paper with code snippets
- 41-page figure/table-heavy paper
- 90-page key field paper

Results: ALL TESTS PASSED
- No errors, timeouts, or truncation issues
- PDF parsing robust across different formats
- Consistent output size (65-106 lines, ~2.6-3.8K)
- max_tokens=4096 is adequate

Infrastructure is solid and ready for production use.

Key insight: Summary length stays relatively consistent regardless of input length.
This is actually ideal - even 90-page papers compress down to ~4K summaries.

Minor issue: Filenames with special characters (smart quotes) need wildcards,
but this is a shell escaping issue, not a tool problem.

Next phase:
- Infrastructure validated, ready to move to quality improvements
- Switch to better model (Sonnet 4.0/4.5) for production
- Consider prompt engineering once quality becomes the focus
- Could add features: research focus, URL download, batch processing

=== 2025-10-28: Switch to Sonnet 4.5 ===

Changed default model from Haiku 3.5 to Sonnet 4.5 for quality work.

Decision: Keep it simple, just change the default. Model selection already
available via -m flag, no need for config file complexity yet.

Initial testing shows significant quality improvement:
- Haiku 3.5: ~80 line summaries
- Sonnet 4.5: ~254 line summaries (3x more comprehensive)
- Much more detailed methodology, specific quotes, statistical values
- Better structure and organization

Minor note: Sonnet 4.5 includes scratchpad in output (prompt artifact).
May want to refine prompt to exclude scratchpad from final output.

Ready to evaluate quality across diverse papers and refine as needed.

=== 2025-10-28: Prompt management infrastructure + scratchpad removal ===

Set up prompt management system:
- Created prompts/ directory with versioned prompt files
- prompts/v1_baseline.txt: original prompt with scratchpad instruction
- prompts/v2_no_scratchpad.txt: removed scratchpad section
- prompts/changelog.txt: tracks changes between versions
- Modified code to load prompts from files via -p flag
- Default now uses v2_no_scratchpad.txt

Research finding: Claude 4.x models think internally by default. The explicit
scratchpad instruction in our prompt was causing it to output planning process.
Solution: simply remove the scratchpad instruction. Model still plans, just
doesn't output it.

Testing confirms scratchpad removed successfully. Output now starts directly
with reference document content, no planning artifacts.

Prompt versioning infrastructure ready for iterative quality improvements.

=== 2025-11-19: Convert to installable package with subcommands ===

Restructured project into proper Python package for system-wide installation.

Package structure:
- nutshell_pkg/ - main package directory
  - __init__.py - package metadata
  - cli.py - command-line interface with subcommand support
  - core.py - core summarization functionality
- setup.py - installation configuration
- MANIFEST.in - ensures Prompts/ directory included in distribution

Command structure:
- Old: python nutshell.py paper.pdf
- New: nutshell summarize paper.pdf

Benefits:
- Can run from any directory after installation
- Cleaner command interface with subcommands
- Extensible for future features (other subcommands can be added)
- Proper package structure for distribution

Installation: pip install -e . (editable mode for development)

Tested successfully: command works from any location, accesses prompts correctly.
